{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Using Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that performs linear regression using gradient descent. The function should take NumPy arrays X (features with a column of ones for the intercept) and y (target) as input, along with learning rate alpha and the number of iterations, and return the coefficients of the linear regression model as a NumPy array. Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    " ```python\n",
    "    input: X = np.array([[1, 1], [1, 2], [1, 3]]), y = np.array([1, 2, 3]), alpha = 0.01,iterations = 1000\n",
    "    output: np.array([0.1107, 0.9513])\n",
    "    reasoning: The linear model is y = 0.0 + 1.0*x, which fits the input data after gradient descent optimization.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n",
    "    # 获取X的shape.\n",
    "    m, n = X.shape\n",
    "    # 初始化权重theta, 这里b已经包含到X中了.\n",
    "    theta = np.zeros((n, 1))\n",
    "    # 迭代更新.\n",
    "    for _ in range(iterations):\n",
    "        # 前向传递，计算损失.\n",
    "        predictions = X @ theta\n",
    "        loss = predictions - y.reshape(-1, 1)\n",
    "        gradients = X.T @ loss / m\n",
    "        theta -= alpha * gradients\n",
    "    return np.round(theta.flatten(), 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xy_ultra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
